---
title: 'Factor Analysis Notes'
output:
github_document:
toc: yes
toc_float: yes
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
source('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_DDM_Analyses/code/SRO_DDM_Analyses_Helper_Functions.R')

test_data_path = '/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_03-29-2018/'

retest_data_path = '/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_03-29-2018/'

input_path = '/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_DDM_Analyses/input/'

library(FactoMineR)
library(missForest)
library(factoextra)
library(cluster)
library(dendextend)
library(colorspace)
library(caret)

op <- par(no.readonly = TRUE)
```

### Load measure labels

```{r}
measure_labels <- read.csv(paste0(input_path, 'measure_labels.csv'))

measure_labels = measure_labels %>% 
  select(-measure_description) %>%
  filter(ddm_task == 1) %>%
  select(-ddm_task) %>%
  filter(rt_acc != "other") %>%
  mutate(dv = as.character(dv),
         overall_difference = factor(overall_difference,levels = c("overall", "difference", "condition"), labels = c("non-contrast", "contrast", "condition")),
         ddm_raw = ifelse(raw_fit == "raw", "raw", "ddm")) %>%
  separate(dv, c("task_group", "var"), sep = "\\.", remove=FALSE, extra = "merge")
```

### Load time 1 data
```{r}
test_data <- read.csv(paste0(test_data_path,'variables_exhaustive.csv'))

test_data_subs = as.character(test_data$X)

test_data = test_data %>%
  select(measure_labels$dv)

test_data$sub_id = test_data_subs

rm(test_data_subs)
```

### Load time 2 data 
```{r}
retest_data <- read.csv(paste0(retest_data_path,'variables_exhaustive.csv'))

retest_data_subs = as.character(retest_data$X)

retest_data = retest_data %>%
  select(measure_labels$dv)

retest_data$sub_id = retest_data_subs

retest_data = retest_data[retest_data$sub_id %in% test_data$sub_id,]

rm(retest_data_subs)
```

### Standardize data and (mean) impute

```{r}
#Standardize datasets
test_data_std = test_data %>% mutate_if(is.numeric, scale)
test_data_std = test_data_std %>% select(-sub_id)

retest_data_std = retest_data %>% mutate_if(is.numeric, scale)
retest_data_std = retest_data_std %>% select(-sub_id)

#mean imputation on standardized data
test_data_std[is.na(test_data_std)]=0
retest_data_std[is.na(retest_data_std)]=0
```

### Clean data

It's probably not great to use 
1. untransformed (though scaled)  
2. highly correlated 
variables.

To reduce the number of variables in a data-driven way (instead of just selecting the variables that went in to the ontology paper)
 I'll apply the cleaning methods from the ontology pipeline - transformation of non-normal variables (should be particularly useful for a set of variables with many response times) and dropping variables with r>0.85.

Remove correlated variables within a task

```{r}
clean_test_data = remove_correlated_task_variables(test_data)
```

Remove outliers (>2.5 SD away)

```{r}
clean_test_data = cbind(sub_id = clean_test_data$sub_id, as.data.frame(apply(clean_test_data[, -which(names(clean_test_data) %in% c("sub_id"))], 2, remove_outliers)))
```

Transform skewed variables

```{r}
numeric_cols = get_numeric_cols()
numeric_cols = numeric_cols[numeric_cols %in% names(clean_test_data) == T]
clean_test_data = transform_remove_skew(clean_test_data, numeric_cols)
```

Drop subject identifier column, mean impute and drop cols with no variance

```{r eval=FALSE}
#Imputation with missForest package - SLOW
test_data_std_miss <- missForest(as.matrix(test_data_std))
```

```{r}
clean_test_data_std = clean_test_data %>% mutate_if(is.numeric, scale)
clean_test_data_std = clean_test_data_std %>% select(-sub_id)

#mean imputation
clean_test_data_std[is.na(clean_test_data_std)]=0

#drop cols with no variance
clean_test_data_std = clean_test_data_std %>%
  select_if(function(col) sd(col) != 0)
```

#Difference between PCA and EFA

>Despite all these similarities, there is a fundamental difference between them: PCA is a linear combination of variables; Factor Analysis is a measurement model of a latent variable.

[Source](https://www.theanalysisfactor.com/the-fundamental-difference-between-principal-component-analysis-and-factor-analysis/)

#PCA

## `FactoMineR` package

Following the tutorial [here](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/)

```{r}
clean_test_pca <- PCA(clean_test_data_std, graph = FALSE, scale.unit = FALSE)
```

```{r}
clean_test_pca
```

Eigenvalues don't go <1 until dimension 90>. 

NOTE: You should have as many eigenvalues as variables (columns) BUT if you fit it to data with more variables than individuals (row) you only have `nrow` eigenvalues.

```{r}
eig_val = get_eigenvalue(clean_test_pca)
nrow(eig_val)
```

```{r}
head(eig_val, 20)
```

Scree plot

```{r}
fviz_eig(clean_test_pca, addlabels = TRUE)
```

```{r}
var <- get_pca_var(clean_test_pca)
var
```

Factor loadings

```{r}
# Coordinates - factor loadings
head(var$coord)
```

Correlation between the variable and the PC - almost the same as above. Not sure where the minor difference comes from.

```{r}
head(var$cor)
```

Cos2: quality on the factore map - squared coordinates: how well the variable is represented by the PC (?)

```{r}
head(var$cos2)
```

Contributions to the principal components - in percentage: how well the variable represents the PC (?)

```{r}
head(as.data.frame(var$contrib)%>% 
       mutate(dv = row.names(.)) %>%
       select(dv, everything()) %>%
       arrange(-Dim.1))
```

Plot variables on first two components and color by their contribution.

```{r}
fviz_pca_var(clean_test_pca, geom=c("point"), col.var = "contrib")
```

Plot variables on first two components and color by their squared loadings.

```{r}
fviz_pca_var(clean_test_pca, geom=c("point"), col.var = "cos2")
```

```{r}
ind <- get_pca_ind(clean_test_pca)
ind
```

Coordinates for individuals - factor scores: how well is a subject represented by a given PC

```{r}
head(ind$coord)
```

Contribution of each individual to each dimension: how well does a subjcet represent a PC

```{r}
head(ind$contrib)
```

Plot individuals on the first two dimensions and color by their contribution. Less structure compared to the plot of variables.

Note n=522 in this plot.

```{r}
fviz_pca_ind(clean_test_pca, geom=c("point"), col.ind="contrib")
```

Plot individuals on the first two dimensions and color by their squared scores.

```{r}
fviz_pca_ind(clean_test_pca, geom=c("point"), col.ind="cos2")
```

Use PCA from test data to predict retest data

```{r}
clean_data_cols = names(clean_test_data_std)
clean_data_cols = gsub(".ReflogTr", "", clean_data_cols)
clean_data_cols = gsub(".logTr", "", clean_data_cols)

clean_data_log_cols = grep("\\.logTr", names(clean_test_data_std), value = T)
clean_data_reflog_cols = grep("\\.ReflogTr", names(clean_test_data_std), value=T)

#Extract the correct dv's from retest data
clean_retest_data_std = retest_data_std %>% select(clean_data_cols)

#Clean extracted retest data the way it has been cleaned for test data
for(i in 1:length(names(clean_retest_data_std))){
  if(names(clean_retest_data_std)[i] %in% gsub(".logTr", "", clean_data_log_cols)){
    clean_retest_data_std[,i]=pos_log(clean_retest_data_std[,i])
    names(clean_retest_data_std)[i] = paste0(names(clean_retest_data_std)[i],".logTr")
    print(paste0("Pos log on ", names(retest_data_std)[i]))
  }
  if(names(clean_retest_data_std)[i] %in% gsub(".ReflogTr", "", clean_data_reflog_cols)){
    clean_retest_data_std[,i]=neg_log(clean_retest_data_std[,i])
    names(clean_retest_data_std)[i] = paste0(names(clean_retest_data_std)[i],".ReflogTr") 
    print(paste0("Neg log on ", names(retest_data_std)[i]))
  }
}

rm(clean_data_cols, clean_data_log_cols, clean_data_reflog_cols,i)

# Check if all names match
# sum(names(clean_retest_data_std) == names(clean_test_data_std))

predict_retest = predict(clean_test_pca, newdata = clean_retest_data_std)
```

```{r}
str(predict_retest)
```

Correlation between factor scores from test and retest

```{r}
data.frame(predict_retest$coord) %>%
  mutate(sub_id = retest_data $sub_id) %>%
  gather(key, value, -sub_id) %>%
  left_join(data.frame(clean_test_pca$ind$coord) %>% 
              mutate(sub_id = clean_test_data$sub_id) %>%
              gather(key, value, -sub_id), by = c("sub_id", "key")) %>%
  ggplot(aes(value.y, value.x))+
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))+
  facet_wrap(~key)+
  xlab("Factor score from test")+
  ylab("Facot score from retest")


```

##`stats` package functions

### `princomp` and `prcomp`  
[Difference between the two](https://stats.stackexchange.com/questions/20101/what-is-the-difference-between-r-functions-prcomp-and-princomp)

> The difference between them is nothing to do with the type of PCA they perform, just the method they use. As the help page for prcomp says:

>The calculation is done by a singular value decomposition of the (centered and possibly scaled) data matrix, not by using eigen on the covariance matrix. This is generally the preferred method for numerical accuracy.

>On the other hand, the princomp help page says:

>The calculation is done using eigen on the correlation or covariance matrix, as determined by cor. This is done for compatibility with the S-PLUS result. A preferred method of calculation is to use svd on x, as is done in prcomp."

>So, prcomp is preferred, although in practice you are unlikely to see much difference (for example, if you run the examples on the help pages you should get identical results).

Using the t1 data for retest participants only with 273 variables and 150 subjects `princomp` doesn't would not work because there are more variables than subjects.

```{r eval=FALSE}
fit <- princomp(test_data_std)
```

Changing to `prcomp` works.

```{r}
fit <- prcomp(clean_test_data_std)
```

Explore components  

For ~70% of the variance you'd need ~30 components. Given that there are 14 tasks is this a good decomposition? If you believe that each task measures multiple cognitive processes then maybe.

```{r}
out = data.frame(t(data.frame((summary(fit)$importance)))) %>%
  mutate(PC = row.names(.),
         PC = factor(as.numeric(gsub("PC", "", PC)))) %>%
  select(PC, everything()) 
out
```

Scree plot

```{r}
out %>%
  filter(as.numeric(as.character(PC))<11)%>%
  ggplot(aes(PC, Proportion.of.Variance)) +
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle = 90))
```

Factor loadings

```{r}
data.frame(fit$rotation)
```

Factor scores (n=522)

```{r}
data.frame(fit$x)
```

Plot variables on first two dimensions

```{r}
data.frame(fit$rotation) %>%
  mutate(dv = row.names(.)) %>%
  ggplot(aes(PC1, PC2, label=dv, col=abs(PC1*PC2)))+
  geom_point()+
  # geom_text(hjust = 0)+
  theme_minimal()+
  geom_hline(aes(yintercept=0))+
  geom_vline(aes(xintercept=0))
```

Plot individuals on first two dimensions

```{r}
data.frame(fit$x) %>%
  mutate(sub_id = test_data$sub_id) %>%
  ggplot(aes(PC1, PC2, label=sub_id, col=abs(PC1*PC2)))+
  geom_point()+
  # geom_text(hjust = 0)+
  theme_minimal()+
  geom_hline(aes(yintercept=0))+
  geom_vline(aes(xintercept=0))+
  xlim(c(-16, 16))
```

##`psych` package functions

```{r}
fit_psych <- principal(clean_test_data_std, nfactors=5, rotate="oblimin")
```

Scree plot from `psych` package

```{r}
data.frame(fit_psych$values) %>%
  rename(eig = fit_psych.values) %>%
  arrange(-eig) %>%
  mutate(var_pct = eig/sum(eig)*100,
         pc = 1:n()) %>%
  filter(pc<11)%>%
  ggplot(aes(pc, var_pct))+
  geom_bar(stat="identity")
```

Factor loadings

```{r}
as.data.frame(fit_psych$loadings[]) %>%
  mutate(dv = row.names(.)) %>%
  select(dv, everything())
```

Factor scores

```{r}
as.data.frame(fit_psych$scores)
```


#EFA

##`stats` package functions

```{r eval=FALSE}
fit_factanal <- factanal(clean_test_data_std, 5, rotate = "promax", n.obs = 0, scores = "regression")
```

##`psych` package functions

```{r eval=F}
#To choose number of factors
parallel <- fa.parallel(clean_test_data_std, fm = 'minres', fa = 'fa')
```

EFA with 5 clusters

```{r}
#doesn't work - 'ml' is the method used in the ontology paper so don't really want to diverge from it
# tmp = fa(test_data_std, 1, rotate='oblimin', fm='ml', n.obs=0, scores='tenBerge')
tmp = fa(clean_test_data_std, 5, rotate='oblimin', fm='minres', n.obs=0, scores='tenBerge')

```

Factor loadings of 5 factor EFA with 0.3 cutoff

```{r}
fa_loadings = as.data.frame(tmp$loadings[])

fa_loadings[abs(fa_loadings)<0.3]=NA

fa_loadings = fa_loadings %>% 
  mutate(dv = row.names(.))%>%
  select(dv, everything()) %>%
  mutate(num_loading = 5-(is.na(MR1)+is.na(MR2)+is.na(MR3)+is.na(MR4)+is.na(MR5))) %>%
  filter(num_loading!=0) %>%
  arrange(-MR1, -MR2, -MR3, -MR4, -MR5) 

fa_loadings
```

Built-in plot for FA (ugly).

```{r}
fa.diagram(tmp)
```

Not a great fit.

```{r}
summary(tmp)
```

What do the factors look like?

```{r}
fa_loadings %>% 
  select(-num_loading) %>%
  arrange(-MR1, -MR2, -MR3, -MR4, -MR5) %>%
  mutate(order_num = 1:n(),
         dv = reorder(dv, -order_num)) %>%
  select(-order_num) %>%
  gather(Factor, Loading, -dv) %>%
  na.exclude() %>%
  mutate(load_sign = factor(ifelse(Loading>0,"pos","neg"))) %>%
  ggplot(aes(dv, abs(Loading), fill=load_sign))+
  geom_bar(stat = "identity")+
  facet_wrap(~Factor, nrow=1)+
  coord_flip()+
  xlab("")+
  theme(legend.position = "none")+
  ylab("Absolute Loading")

ggsave('efa_5.jpeg', device = "jpeg", path = "../output/figures/", width = 10, height = 50, units = "in", limitsize = FALSE, dpi = 100)

```

#Clustering

##`stats` package - kmeans

```{r}
set.seed(230948)

#clustering people
ind_clusters <- kmeans(clean_test_data_std, 5)

str(ind_clusters)
data.frame(ind_clusters$centers)
```

```{r}
var_clusters <- kmeans(t(clean_test_data_std),5)
```

```{r}
tmp = data_frame(cluster = var_clusters$cluster, dv = names(clean_test_data_std)) %>%
  select(dv, cluster) %>%
  mutate(dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv))%>%
  left_join(measure_labels[,c("dv", "task_group","overall_difference","raw_fit","rt_acc", "ddm_raw")], by = "dv")%>%
    mutate(dv = reorder(dv, -cluster))

tmp %>%
  ggplot(aes(dv, cluster, alpha = ddm_raw, fill=rt_acc))+
  geom_bar(stat="identity")+
  coord_flip()+
  xlab("")+
  scale_alpha_discrete(range = c(0.4, 0.8))

ggsave('kmeans_5_clusters.jpeg', device = "jpeg", path = "../output/figures/", width = 10, height = 50, units = "in", limitsize = FALSE, dpi = 100)

```

```{r}
with(tmp, table(rt_acc, ddm_raw, cluster))
```


##`cluster` package - hclust

Cluster all (hddm, ez, raw) variables without projecting to a lower dimensional space. [pretty ugly]

```{r eval=FALSE}
#Same thing done later with chaining in separate steps
clean_test_data_std_dist = stats::dist(t(clean_test_data_std))

hclust_out = hclust(clean_test_data_std_dist)
```

```{r}
dend = t(clean_test_data_std) %>%
  dist %>%
  hclust %>%
  as.dendrogram

rt_acc_cols <- rainbow_hcl(5)

tmp = data.frame(dv = dend %>% labels) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc")], by="dv") %>%
  mutate(cols = ifelse(rt_acc == "rt", rt_acc_cols[1], ifelse(rt_acc == "accuracy", rt_acc_cols[2], ifelse(rt_acc == "drift rate", rt_acc_cols[3], ifelse(rt_acc == "non-decision", rt_acc_cols[4], ifelse(rt_acc == "threshold", rt_acc_cols[5], NA)))))) %>%
  select(-dv) %>%
  rename(dv = dv2)

# tmp[is.na(tmp$cols),]

dend2 <- dend %>% 
  set("leaves_pch", 19) %>% 
  set("leaves_cex", 1) %>% 
  set("leaves_col", tmp$cols)%>% 
  color_labels(col = tmp$cols) %>%
  set("labels", rep(NA,419))

plot(dend2, axes=FALSE)
```

Project on lower dimensional space and then cluster

```{r}
clean_test_data_low_dim = clean_test_pca$var$coord

#no transpose because dv's are in rows
dend = clean_test_data_low_dim%>%
  dist %>%
  hclust %>%
  as.dendrogram

rt_acc_cols <- rainbow_hcl(5)

tmp = data.frame(dv = dend %>% labels) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc")], by="dv") %>%
  mutate(cols = ifelse(rt_acc == "rt", rt_acc_cols[1], ifelse(rt_acc == "accuracy", rt_acc_cols[2], ifelse(rt_acc == "drift rate", rt_acc_cols[3], ifelse(rt_acc == "non-decision", rt_acc_cols[4], ifelse(rt_acc == "threshold", rt_acc_cols[5], NA)))))) %>%
  select(-dv) %>%
  rename(dv = dv2)

# tmp[is.na(tmp$cols),]

dend2 <- dend %>% 
  set("leaves_pch", 19) %>% 
  set("leaves_cex", 1) %>% 
  set("leaves_col", tmp$cols)%>% 
  color_labels(col = tmp$cols) %>%
  set("labels", rep(NA,419))

plot(dend2, axes=FALSE)
```

# Neuroecon Poster

## PCA on EZ vars (3 factors)

```{r}
ez_vars = grep("EZ", names(clean_test_data_std), value=T)

ez_pca <- PCA(clean_test_data_std %>% select(ez_vars), ncp=3, graph = FALSE, scale.unit = FALSE)

fviz_eig(ez_pca, addlabels = TRUE)
```

```{r}
data.frame(ez_pca$var$coord) %>%
  mutate(dv = row.names(.)) %>%
  select(dv, everything())%>%
  arrange(-Dim.3)
```

Hierarchical clustering of PCA loadings of EZ vars

```{r}
ez_var_low_dim = ez_pca$var$coord

dend = ez_var_low_dim %>%
  dist %>%
  hclust %>%
  as.dendrogram

rt_acc_cols <- rainbow_hcl(3)
overall_diff_cols <- rainbow_hcl(3)

tmp = data.frame(dv = dend %>% labels) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc", "overall_difference")], by="dv") %>%
  mutate(rt_acc_cols = ifelse(rt_acc == "drift rate", rt_acc_cols[1], ifelse(rt_acc == "non-decision", rt_acc_cols[2], ifelse(rt_acc == "threshold", rt_acc_cols[3], NA))),
         overall_diff_cols = ifelse(overall_difference == "non-contrast", overall_diff_cols[1], ifelse(overall_difference == "contrast", overall_diff_cols[2], ifelse(overall_difference == "condition", overall_diff_cols[3], NA)))) %>%
  select(-dv) %>%
  rename(dv = dv2)

dend2 <- dend %>% 
  set("leaves_pch", 19) %>% 
  set("leaves_cex", 2) %>% 
  set("leaves_col", tmp$rt_acc_cols)%>% 
  # color_labels(col = rt_acc_cols) 
  #color_labels(col = tmp$overall_diff_cols) 
# %>%
  set("labels", rep(NA,164))

plot(dend2, axes=FALSE)
```

```{r}
ez_groups_3 = cutree(dend,3)
table(ez_groups_3)
```

```{r}
aggregate(ez_var_low_dim,list(ez_groups_3),median)
```

Plot T-1 PCA in 3D space

```{r}
tmp = data.frame(ez_var_low_dim) %>%
  mutate(dv = row.names(.)) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc", "overall_difference")], by="dv") %>%
  mutate(rt_acc_cols = ifelse(rt_acc == "drift rate", rt_acc_cols[1], ifelse(rt_acc == "non-decision", rt_acc_cols[2], ifelse(rt_acc == "threshold", rt_acc_cols[3], NA)))) %>%
  select(-dv) %>%
  rename(dv = dv2)
```


Static 3D

`plot3D` package

Coloring doesn't seem to work right

```{r}
scatter3D(tmp$Dim.1, tmp$Dim.2, tmp$Dim.3, pch = 19, 
          col.var = as.integer(factor(tmp$rt_acc)), 
          #col = tmp$rt_acc_cols,
          colkey = list(plot = FALSE),
          phi = 15, theta = 0)
```

Rotatable plots

`plotly` package

```{r}
a = list(title = "", tickfont = list(size=20))

plot_ly(tmp, x = ~Dim.1, y = ~Dim.2, z = ~Dim.3, color = ~rt_acc, text = ~dv, colors = c('#4AC6B7', '#965F8A', '#C61951')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = a,
                      yaxis = a,
                      zaxis = a))
```

```{r}
ez_retest_pca <- PCA(clean_retest_data_std %>% select(ez_vars), ncp=3, graph = FALSE, scale.unit = FALSE)

tmp2 = data.frame(ez_retest_pca$var$coord) %>%
  mutate(dv = row.names(.)) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc", "overall_difference")], by="dv") %>%
  select(-dv) %>%
  rename(dv = dv2)

plot_ly(tmp2, x = ~Dim.1, y = ~Dim.2, z = ~Dim.3, color = ~rt_acc, text = ~dv, colors = c('#4AC6B7', '#965F8A', '#C61951')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = a,
                      yaxis = a,
                      zaxis = a))
```

`rgl` package

```{r}
plot3d(tmp$Dim.1, tmp$Dim.2, tmp$Dim.3, size=12,
       xlab = "threshold",
       ylab = "non-decision",
       zlab = "drift rate",
       col = tmp$rt_acc_cols)

identify3d(x=-0.5, y=0.3, z=)
```

`car` package

```{r}
scatter3d(tmp$Dim.1, tmp$Dim.2, tmp$Dim.3, pch = 19, 
          col = rt_acc_cols)
```

### Interdimension reliability comparison

Are Lower dimensional factor scores are better individual difference factors? - compare their reliability

```{r}
predict_ez_retest = predict(ez_pca, newdata = clean_retest_data_std %>% select(ez_vars))

data.frame(predict_ez_retest$coord) %>%
  mutate(sub_id = retest_data$sub_id) %>%
  gather(key, value, -sub_id) %>%
  left_join(data.frame(ez_pca$ind$coord) %>% 
              mutate(sub_id = clean_test_data$sub_id) %>%
              gather(key, value, -sub_id), by = c("sub_id", "key")) %>%
  ggplot(aes(value.y, value.x))+
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))+
  facet_wrap(~key)+
  xlab("Factor score from test")+
  ylab("Factor score from retest")
```

Calculate reliabilities of the factor scores

```{r}
clean_test_data_std$sub_id = test_data$sub_id

test_data = clean_test_data_std[clean_test_data_std$sub_id %in% retest_data$sub_id,]
test_data = test_data %>% select(sub_id, ez_vars)

clean_retest_data_std$sub_id = retest_data$sub_id
retest_data = clean_retest_data_std
retest_data = retest_data %>% select(sub_id,ez_vars)

numeric_cols = get_numeric_cols()

#Create df of point estimate reliabilities
rel_df_cols = c('icc', 'pearson', 'var_subs', 'var_ind', 'var_resid', 'dv')

rel_df = as.data.frame(matrix(ncol = length(rel_df_cols)))

names(rel_df) = rel_df_cols

for(i in 1:length(numeric_cols)){
  
  cur_dv = numeric_cols[i]
  
  tmp = get_retest_stats(cur_dv, metric = c('icc', 'pearson', 'var_breakdown'))
  
  if(nrow(tmp) == 0){
    tmp[1,]=NA
    tmp$dv = NA
  } else {
    tmp$dv = cur_dv
  }
  
  rel_df = rbind(rel_df, tmp)
  
}

rel_df= rel_df[-which(is.na(rel_df$dv)),]
```

```{r}
rel_df_dvs = rel_df
rel_df_dvs
```

Reliability between PCA from T1 and T2

```{r}
tmp1 = data.frame(ez_pca$ind$coord) %>%
  mutate(sub_id = clean_test_data$sub_id) %>%
  rename(drift_rate = Dim.3, non_decision = Dim.2, threshold = Dim.1)

tmp2 = data.frame(ez_retest_pca$ind$coord) %>%
  mutate(sub_id = retest_data$sub_id) %>%
  rename(drift_rate = Dim.3, non_decision = Dim.2, threshold = Dim.1)

rel_df_factors = data_frame(drift_rate = get_retest_stats("drift_rate",t1_df = tmp1, t2_df = tmp2, metric="icc")$icc,
           non_decision = get_retest_stats("non_decision",t1_df = tmp1, t2_df = tmp2, metric="icc")$icc,
           threshold = get_retest_stats("threshold",t1_df = tmp1, t2_df = tmp2, metric="icc")$icc) %>%
  gather(dim_name, icc)
```


Reliability of predicted factor scores in T2 using T1 PCA

```{r}
test_data = data.frame(ez_pca$ind$coord) %>% 
              mutate(sub_id = clean_test_data$sub_id)

retest_data = data.frame(predict_ez_retest$coord) %>%
  mutate(sub_id = retest_data$sub_id)

test_data = test_data %>% filter(sub_id %in% retest_data$sub_id)

numeric_cols = get_numeric_cols()

rel_df = as.data.frame(matrix(ncol = length(rel_df_cols)))

names(rel_df) = rel_df_cols

for(i in 1:length(numeric_cols)){
  
  cur_dv = numeric_cols[i]
  
  tmp = get_retest_stats(cur_dv, metric = c('icc', 'pearson', 'var_breakdown'))
  
  if(nrow(tmp) == 0){
    tmp[1,]=NA
    tmp$dv = NA
  } else {
    tmp$dv = cur_dv
  }
  
  rel_df = rbind(rel_df, tmp)
  
}

rel_df= rel_df[-which(is.na(rel_df$dv)),]
```

```{r}
rel_df_factors = rel_df
rel_df_factors = rel_df_factors %>%
  mutate(dim_name = c("threshold", "non-decision", "drift_rate"))
rel_df_factors
```

```{r}
rel_df_dvs %>%
  left_join(measure_labels[,c("dv", "rt_acc")], by="dv") %>%
  ggplot(aes(icc, fill=rt_acc))+
  geom_density(position="identity",alpha=0.5, color=NA)+
  theme(legend.title = element_blank(),
        legend.position = "bottom")+
  xlab("Retest reliability")+
  scale_fill_manual(values=c('#4AC6B7', '#965F8A', '#C61951'))+
  geom_vline(xintercept=rel_df_factors$icc[rel_df_factors$dim_name=="drift_rate"], color="#4AC6B7", size=1.5)+
  geom_vline(xintercept=rel_df_factors$icc[rel_df_factors$dim_name=="non_decision"], color="#965F8A", size=1.5)+
  geom_vline(xintercept=rel_df_factors$icc[rel_df_factors$dim_name=="threshold"], color="#C61951", size=1.5)+
  xlim(-1, 1)
```

```{r}
rel_df_dvs %>%
  left_join(measure_labels[,c("dv", "rt_acc")], by="dv") %>%
  group_by(rt_acc) %>%
  summarise(median_icc = median(icc))
```

## PCA on HDDM vars (3 factors)

```{r}
hddm_vars = grep("hddm", names(clean_test_data_std), value=T)

hddm_pca <- PCA(clean_test_data_std %>% select(hddm_vars), ncp=3, graph = FALSE, scale.unit = FALSE)

fviz_eig(hddm_pca, addlabels = TRUE)
```

Hierarchical clustering of PCA loadings of HDDM vars

```{r}
hddm_var_low_dim = hddm_pca$var$coord

dend = hddm_var_low_dim %>%
  dist %>%
  hclust %>%
  as.dendrogram

rt_acc_cols <- rainbow_hcl(3)
overall_diff_cols <- rainbow_hcl(3)

tmp = data.frame(dv = dend %>% labels) %>%
  mutate(dv2 = dv,
         dv = gsub(".ReflogTr", "", dv),
         dv = gsub(".logTr", "", dv)) %>%
  left_join(measure_labels[,c("dv", "rt_acc", "overall_difference")], by="dv") %>%
  mutate(rt_acc_cols = ifelse(rt_acc == "drift rate", rt_acc_cols[1], ifelse(rt_acc == "non-decision", rt_acc_cols[2], ifelse(rt_acc == "threshold", rt_acc_cols[3], NA))),
         overall_diff_cols = ifelse(overall_difference == "non-contrast", overall_diff_cols[1], ifelse(overall_difference == "contrast", overall_diff_cols[2], ifelse(overall_difference == "condition", overall_diff_cols[3], NA)))) %>%
  select(-dv) %>%
  rename(dv = dv2)

dend2 <- dend %>% 
  set("leaves_pch", 19) %>% 
  set("leaves_cex", 1) %>% 
  set("leaves_col", tmp$rt_acc_cols)%>% 
  # color_labels(col = rt_acc_cols) 
  #color_labels(col = tmp$overall_diff_cols) 
# %>%
   set("labels", rep(NA,90))
plot(dend2, axes=FALSE)
```

Correlation of the factor scores between these two lower dimensional spaces doesn't seem like a good idea because while the EZ clusters map somewhat on the parameters the hddm clusters have two distinct drift rate clusters and a mixed thresh/non-decision cluster. This is partially because there are more non-decision times and thresholds from the EZ estimations because we didn't allow all parameters to vary for the hddm's.

## Prediction

DV's: factor scores of demographics in T1

```{r}
demog_data = read.csv(paste0(test_data_path, 'demographic_health.csv'))

demog_data=demog_data %>%
  rename(sub_id = X) %>%
  mutate(BMI = 703*(HeightInches/WeightPounds^2),
         Obese = ifelse(BMI>=30, 1, 0))

demog_vars = c("ChildrenNumber", "LongestRelationship","HighestEducation" ,"RentOwn","RetirementAccount","HouseholdIncome","TeaCupsPerDay","CaffienatedSodaCansPerDay","BMI","Obese","RelationshipStatus",'Last30DaysUsual',"RestlessFidgety","Nervous","EverythingIsEffort","Worthless","Hopeless","Depressed","TrafficTicketsLastYearCount","CoffeeCupsPerDay","HowSoonSmokeAfterWaking","SmokeEveryDay","CigsPerDay","HowLongSmoked","LifetimeSmoke100Cigs","CaffieneOtherSourcesDayMG","AbleToStopDrugs","GamblingProblem","MedicalProblemsDueToDrugUse","AbuseMoreThanOneDrugAtATime","BlackoutFlashbackDrugUse","FeelBadGuiltyDrugUse","EngagedInIllegalActsToObtainDrugs","SpouseParentsComplainDrugUse","WidthdrawalSymptoms","NeglectedFamilyDrugUse","TrafficAccidentsLifeCount","CannabisPast6Months","ArrestedChargedLifeCount","RelationshipNumber","RelativeFriendConcernedDrinking","InjuredDrinking","HowOftenUnableRememberDrinking","HowOftenGuiltRemorseDrinking","HowOftenCantStopDrinking","HowOftenDrinkMorning","HowOftenFailedActivitiesDrinking","DivorceCount","AlcoholHowOften","AlcoholHowManyDrinksDay","AlcoholHowOften6Drinks")

demog_dvs = demog_data %>% select(demog_vars)

demog_dvs_std = demog_dvs %>% mutate_if(is_numeric, scale)

demog_fa = fa(demog_dvs_std, 9, rotate='oblimin', fm='ml', n.obs=0, scores='tenBerge')
```

```{r}
data.frame(demog_fa$loadings[]) %>%
  mutate(dv = row.names(.)) %>%
  select(dv, ML1, ML2, ML3, ML4, ML5, ML6, ML7, ML8, ML9) %>%
  rename(Obesity = ML1,
         Daily_Smoking=ML2,
         Problem_Drinking=ML3,
         Mental_Health=ML4,
         Drug_Use=ML5,
         Lifetime_Smoking=ML6,
         Binge_Drinking=ML7,
         Unsafe_Drinking=ML8,
         Income=ML9) %>%
  arrange(-Daily_Smoking)
```

```{r}
demog_fa_scores = data.frame(demog_fa$scores[]) %>%
  mutate(sub_id = demog_data$sub_id) %>%
  select(sub_id, ML1, ML2, ML3, ML4, ML5, ML6, ML7, ML8, ML9) %>%
  rename(Obesity = ML1,
         Daily_Smoking=ML2,
         Problem_Drinking=ML3,
         Mental_Health=ML4,
         Drug_Use=ML5,
         Lifetime_Smoking=ML6,
         Binge_Drinking=ML7,
         Unsafe_Drinking=ML8,
         Income=ML9)

demog_fa_scores
```

Covariates: Age, sex

IV's: EZ measures vs. EZ factors in T1

Comparison: Distribution of cross-validated R^2 for EZ dv predictions vs EZ factor predictions

```{r}
ez_measures_pred = read.csv(paste0(input_path, 'ez_measures_pred.csv'))
ez_factors_pred = read.csv(paste0(input_path, 'ez_factors_pred.csv'))

ez_measures_pred = ez_measures_pred %>% na.exclude()
ez_factors_pred = ez_factors_pred %>% na.exclude()

tmp1=ez_factors_pred %>%
  group_by(dv) %>%
  summarise(mean_r2 = mean(Rsquared),
            sem_r2 = sem(Rsquared)) %>%
  mutate(pred="factor")

tmp2 = ez_measures_pred %>%
  group_by(dv) %>%
  summarise(mean_r2 = mean(Rsquared), #%>%
            sem_r2 = sem(Rsquared)) %>%
  mutate(pred = "measure")

rbind(tmp1,tmp2) %>%
  ggplot(aes(dv, mean_r2, fill=pred))+
  geom_bar(stat="identity", position = position_dodge(width = 0.9))+
  geom_errorbar(aes(ymin=mean_r2-sem_r2, ymax = mean_r2+sem_r2),position = position_dodge(width = 0.9), width = 0.25)+
  xlab("")+
  ylab(expression('Mean R'^2))+
  theme(legend.position = "bottom",
        legend.title = element_blank())

# rbind(ez_factors_pred %>% 
#         select(-RsquaredSD) %>%
#         rename(mean_r2=Rsquared,
#                pred = iv) %>%
#         select(dv, mean_r2, pred)
#       ,tmp2) %>%
#   ggplot(aes(dv, mean_r2, fill=pred))+
#   geom_bar(stat="identity", position = position_dodge(width = 0.9))+
#   # geom_errorbar(aes(ymin=mean_r2-sem_r2, ymax = mean_r2+sem_r2),position = position_dodge(width = 0.9), width = 0.25)+
#   xlab("")+
#   ylab(expression('Mean R'^2))+
#   theme(legend.position = "bottom",
#         legend.title = element_blank())
```


```{r echo=FALSE}
par(op)
```

# Concepts

- eigenvalue: amount of variance explained by each PC  
- coordinate/correlation: the correlation between the variable and the PC  
- quality of representation: squared correlation; how well the variable is represented by the PC; variance of variable explained by the PC  
- contribution: varianc of PC explained by the variable
- Factor loadings (aka rotation) (variables)     
- Factor scores (individuals)

# Resources

[PCA Essentials](http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/112-pca-principal-component-analysis-essentials/)
[Difference between PCA and EFA](http://www2.sas.com/proceedings/sugi30/203-30.pdf)
[K-means clustering hands-on tutorial](https://www.datacamp.com/community/tutorials/k-means-clustering-r)